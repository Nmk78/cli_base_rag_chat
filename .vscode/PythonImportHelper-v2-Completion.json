[
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "CSVLoader",
        "importPath": "langchain_community.document_loaders",
        "description": "langchain_community.document_loaders",
        "isExtraImport": true,
        "detail": "langchain_community.document_loaders",
        "documentation": {}
    },
    {
        "label": "OllamaEmbeddings",
        "importPath": "langchain_ollama",
        "description": "langchain_ollama",
        "isExtraImport": true,
        "detail": "langchain_ollama",
        "documentation": {}
    },
    {
        "label": "OllamaLLM",
        "importPath": "langchain_ollama",
        "description": "langchain_ollama",
        "isExtraImport": true,
        "detail": "langchain_ollama",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain_chroma",
        "description": "langchain_chroma",
        "isExtraImport": true,
        "detail": "langchain_chroma",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain_chroma",
        "description": "langchain_chroma",
        "isExtraImport": true,
        "detail": "langchain_chroma",
        "documentation": {}
    },
    {
        "label": "load_config",
        "importPath": "src.config_loader",
        "description": "src.config_loader",
        "isExtraImport": true,
        "detail": "src.config_loader",
        "documentation": {}
    },
    {
        "label": "load_config",
        "importPath": "src.config_loader",
        "description": "src.config_loader",
        "isExtraImport": true,
        "detail": "src.config_loader",
        "documentation": {}
    },
    {
        "label": "RetrievalQA",
        "importPath": "langchain.chains",
        "description": "langchain.chains",
        "isExtraImport": true,
        "detail": "langchain.chains",
        "documentation": {}
    },
    {
        "label": "BaseLLM",
        "importPath": "langchain_core.language_models",
        "description": "langchain_core.language_models",
        "isExtraImport": true,
        "detail": "langchain_core.language_models",
        "documentation": {}
    },
    {
        "label": "BaseRetriever",
        "importPath": "langchain_core.retrievers",
        "description": "langchain_core.retrievers",
        "isExtraImport": true,
        "detail": "langchain_core.retrievers",
        "documentation": {}
    },
    {
        "label": "build_rag_chain",
        "importPath": "src.rag_chain",
        "description": "src.rag_chain",
        "isExtraImport": true,
        "detail": "src.rag_chain",
        "documentation": {}
    },
    {
        "label": "get_vector_store",
        "importPath": "src.prep",
        "description": "src.prep",
        "isExtraImport": true,
        "detail": "src.prep",
        "documentation": {}
    },
    {
        "label": "load_config",
        "kind": 2,
        "importPath": "src.config_loader",
        "description": "src.config_loader",
        "peekOfCode": "def load_config(config_path: str = \"config.yaml\") -> dict:\n    \"\"\"\n    Loads and parses the YAML configuration file.\n    Args:\n        config_path (str): The path to the configuration file.\n    Returns:\n        dict: A dictionary containing the configuration settings.\n    Raises:\n        FileNotFoundError: If the configuration file does not exist.\n        yaml.YAMLError: If there is an error parsing the YAML file.",
        "detail": "src.config_loader",
        "documentation": {}
    },
    {
        "label": "get_vector_store",
        "kind": 2,
        "importPath": "src.prep",
        "description": "src.prep",
        "peekOfCode": "def get_vector_store():\n    print(\"Initializing vector store...\")\n    try:\n        vectorStore = Chroma(\n            collection_name=config['retriever']['collection_name'],\n            embedding_function=embedding,\n            persist_directory=config['retriever']['persist_directory']\n        )\n        print(\"Vector store initialized successfully.\")\n        return vectorStore",
        "detail": "src.prep",
        "documentation": {}
    },
    {
        "label": "add_data_to_vector_store",
        "kind": 2,
        "importPath": "src.prep",
        "description": "src.prep",
        "peekOfCode": "def add_data_to_vector_store(chunks):\n    print(\"Adding data to vector store...\")\n    try:\n        vectorStore = get_vector_store()\n        vectorStore.add_documents(chunks)\n    except Exception as e:\n        print(f\"An error occurred while adding data to the vector store: {e}\")\n        return False\n    print(\"Data added to vector store successfully.\")\ndef load_and_add_data(path):",
        "detail": "src.prep",
        "documentation": {}
    },
    {
        "label": "load_and_add_data",
        "kind": 2,
        "importPath": "src.prep",
        "description": "src.prep",
        "peekOfCode": "def load_and_add_data(path):\n    if not os.path.exists(path):\n        raise FileNotFoundError(\"The specified file does not exist.\")\n    print(\"Loading data...\")\n    loader = CSVLoader(path, encoding=\"utf-8\")\n    chunks = loader.load_and_split()\n    print(f\"Loaded {len(chunks)} chunks from the CSV file.\")\n    print(f\"First 2 chunks {chunks[:2]} \")",
        "detail": "src.prep",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "src.prep",
        "description": "src.prep",
        "peekOfCode": "config = load_config()\npath = \"data/cybersecurity.csv\"\nembedding = OllamaEmbeddings(model=config['llm']['embedding_model'])\ndef get_vector_store():\n    print(\"Initializing vector store...\")\n    try:\n        vectorStore = Chroma(\n            collection_name=config['retriever']['collection_name'],\n            embedding_function=embedding,\n            persist_directory=config['retriever']['persist_directory']",
        "detail": "src.prep",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "src.prep",
        "description": "src.prep",
        "peekOfCode": "path = \"data/cybersecurity.csv\"\nembedding = OllamaEmbeddings(model=config['llm']['embedding_model'])\ndef get_vector_store():\n    print(\"Initializing vector store...\")\n    try:\n        vectorStore = Chroma(\n            collection_name=config['retriever']['collection_name'],\n            embedding_function=embedding,\n            persist_directory=config['retriever']['persist_directory']\n        )",
        "detail": "src.prep",
        "documentation": {}
    },
    {
        "label": "embedding",
        "kind": 5,
        "importPath": "src.prep",
        "description": "src.prep",
        "peekOfCode": "embedding = OllamaEmbeddings(model=config['llm']['embedding_model'])\ndef get_vector_store():\n    print(\"Initializing vector store...\")\n    try:\n        vectorStore = Chroma(\n            collection_name=config['retriever']['collection_name'],\n            embedding_function=embedding,\n            persist_directory=config['retriever']['persist_directory']\n        )\n        print(\"Vector store initialized successfully.\")",
        "detail": "src.prep",
        "documentation": {}
    },
    {
        "label": "build_rag_chain",
        "kind": 2,
        "importPath": "src.rag_chain",
        "description": "src.rag_chain",
        "peekOfCode": "def build_rag_chain(llm: BaseLLM, retriever: BaseRetriever):\n    return RetrievalQA.from_chain_type(\n        llm=llm,\n        retriever=retriever,\n    )",
        "detail": "src.rag_chain",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "config = load_config()\nfrom langchain_ollama import OllamaLLM\nfrom langchain_chroma import Chroma\nfrom src.rag_chain import build_rag_chain\nfrom src.prep import get_vector_store\n# Initialize LLM\nllm = OllamaLLM(model=config['llm']['model'], temperature=config['llm']['temperature'], max_tokens=config['llm']['max_tokens'])\n# Load vector DB retriever\nvectorStore = get_vector_store()\nretriever = vectorStore.as_retriever(",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "llm",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "llm = OllamaLLM(model=config['llm']['model'], temperature=config['llm']['temperature'], max_tokens=config['llm']['max_tokens'])\n# Load vector DB retriever\nvectorStore = get_vector_store()\nretriever = vectorStore.as_retriever(\n    search_kwargs={\n        \"k\": 5,  # Number of documents to retrieve\n    }\n)\n# Build the chain\nqa_chain = build_rag_chain(llm, retriever)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "vectorStore",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "vectorStore = get_vector_store()\nretriever = vectorStore.as_retriever(\n    search_kwargs={\n        \"k\": 5,  # Number of documents to retrieve\n    }\n)\n# Build the chain\nqa_chain = build_rag_chain(llm, retriever)\nwhile True:\n    try:",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "retriever",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "retriever = vectorStore.as_retriever(\n    search_kwargs={\n        \"k\": 5,  # Number of documents to retrieve\n    }\n)\n# Build the chain\nqa_chain = build_rag_chain(llm, retriever)\nwhile True:\n    try:\n        query = input(\"\\n❓ Ask a question (or type 'exit' to quit):\\n> \")",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "qa_chain",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "qa_chain = build_rag_chain(llm, retriever)\nwhile True:\n    try:\n        query = input(\"\\n❓ Ask a question (or type 'exit' to quit):\\n> \")\n        if query.lower() in [\"exit\", \"quit\"]:\n            print(\"👋 Goodbye!\")\n            break\n        response = qa_chain.invoke(query)\n        # print(response)\n        print(\"\\n💬 Answer:\\n\" + response['result'])",
        "detail": "app",
        "documentation": {}
    }
]